#+INCLUDE: ../header.org
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="../timeline.css"/>
#+TOC: headlines 3

* Table of Contents                                          :TOC@3:noexport:
- [[#requirements-and-setup][Requirements and Setup]]
  - [[#source-of-the-lab][Source of the Lab]]
  - [[#environment][Environment]]
    - [[#set-the-experimental-environment][Set the experimental environment]]
  - [[#finish-the-initialization-of-openstack][Finish the initialization of OpenStack]]
    - [[#access-horizon][Access Horizon]]
    - [[#vm-ping-the-internet][VM ping the Internet]]
- [[#omh----online-mines-hosting][OMH -- Online Mines Hosting]]
  - [[#clean-the-environment][Clean the environment]]
- [[#automatize-the-deployment-with-heat][Automatize the deployment with Heat]]
- [[#appendix][Appendix]]
  - [[#reservationyaml][reservation.yaml]]
  - [[#patchgaleracnf][patch/galera.cnf]]
  - [[#installs-mariadb-on-debian-9][Installs MariaDB on Debian 9]]
  - [[#installs-wordpress-on-debian-9][Installs Wordpress on Debian 9]]
- [[#footnotes][Footnotes]]

* Requirements and Setup
** Source of the Lab
Get the source of lab at [[http://enos.irisa.fr/tp-imt/tp-imt.tar.gz]].
#+BEGIN_SRC bash
$ curl -O http://enos.irisa.fr/tp-imt/tp-imt.tar.gz
$ tar xf tp-imt
$ cd tp-imt/day2/lib
#+END_SRC

** Environment
:PROPERTIES:
:CUSTOM_ID: sec:ovh
:END:
To follow the lab you'll need an OVH account[fn:ovh]. OVH is a French company
providing Cloud computing and hosting services. Founded in 1999, its
headquarters are located in Roubaix. OVH has provided us some vouchers that can
be used to deploy resources during this session. You will quickly notice that
OVH public Cloud is based on standard cloud technologies. More particularly, the
infrastructure management is managed by OpenStack ðŸ˜„.

For this lab, we are going to build a Platform as a Service (PaaS) over the OVH
infrastructure. To that end, we will deploy our own OpenStack on OVH to manage
the deployment and the management of real applications.

During the last session, you deployed all the OpenStack services in a single
virtual machine. Let's start gently by deploying OpenStack over two virtual
machines. To that end, you will need first to set an experimental environment
composed of two virtual machine (called ~os-control~ and ~os-compute1~)
from the OVH public Cloud interface, interconnected by a private network. Since
you are now familiar with EnOS[fn:enos-paper][fn:enos-code], we are going to run
it from the first VM to deploy the OpenStack services on our OVH VMs.

During the last session, we used EnOS to deploy the three following groups of
OpenStack services in a single VM:
- ~vagrant_machine~:
  + ~control~
  + ~compute~
  + ~network~

Today, we are going to repeat this operation for the first OVH VM, and we will
deploy only the compute services to the second one, as depicted here:
- ~os-control~:
  + ~control~
  + ~network~
- ~os-compute1~:
  + ~compute~

The following depicts the status of the different components in play during the
lab.

#+BEGIN_EXAMPLE
+---------------------------------------+
|          OVH Public Cloud             |
|                                       |
|                                       |
|   +---------------------------+       |
|   |  os-control VM            |       |
|   |     ~/rsc <- - - - - -  - - - - - - - - - -  EnOS sources & configuration files
|   |                           |       |
|   |  * docker container 1 +   |       |
|   |  * docker container 2 +   |       |
|   |  * ...                +- - - - - - - - - - - Docker containers launched by EnOS
|   |  * docker container n +   |       |          (Openstack control/compute/network
|   |                           |       |          services + third-party services)
|   +---------------------------+       |

|   +---------------------------+       |
|   |      os-compute1 VM       |       |
|   |                           |       |
|   |  * docker container 1 +   |       |
|   |  * docker container 2 +   |       |
|   |  * ...                +- - - - - - - - - - - Docker containers launched by
|   |  * docker container n +   |       |          EnOS (Openstack compute services
|   |                           |       |          + third-party services)
|   +---------------------------+       |
+---------------------------------------+
#+END_EXAMPLE

*** Set the experimental environment
**** Create a new project
Please be sure you have created an OVH account prior the session. Once
you are logged in, reach the OVH public Cloud interface [fn:ovh].
Click on ~Order > Cloud project > Create the project~ (~Commander >
Projet Cloud > CrÃ©er le projet~) to create a new project, by giving a
name and the voucher (~7ZA6-AFGP~) provided by OVH. Mind that this
project will only be active during our session. You can now access
your project: ~Servers > 'ProjectName' > Infrastructure~.
~Infrastructure~ will be the main panel for us during this session.

**** Set the private network
OVH provides their VMs with a public address which is reachable from the
Internet. However, our VMs are going to communicate together so we would like to
set a private network to that end. To create a virtual network, few steps are
required [fn:ovh-vrack-doc]:
1. Create a OVH vRack;
2. Attach our new project to the vRack;
3. Create a virtual network.

The voucher enables you to create an OVH vRack for free during this session. Its
creation requires an order which can take few minutes to be validated by OVH.

Once it is created, you can reach the ~vRack~ panel and add your new project in
it [fn:ovh-vrack]. Once it is added, go back to the ~Infrastructure~ panel.
From here, you can notice that private network creation is now available.

#+BEGIN_NOTE
As discussed above, the OVH public Cloud is operated with OpenStack. The OVH web
interface is similar to the Horizon you played with during the previous session.
Creating a private network from this interface sends to the OVH OpenStack a
request to create a private network. To convince you that the OVH public Cloud
is powered by OpenStack, click on the ~OpenStack Client~ at the bottom of this
interface to reach a terminal from which you can use the OpenStack CLI just like
you did in our first session.
#+END_NOTE

***** Create a private network
Create a private network (using either the interface or the CLI) with the
following characteristics:
- name: ~provider-net~
- *No* VLAN
- *No* dhcp
- Only on Gravelines
- address: 192.168.0.0
- mask: 255.255.255.0

#+BEGIN_NOTE
You can both validate the network creation from the web interface and
from the CLI by typing: ~openstack network list~ and ~openstack
network show <network_name>~.
#+END_NOTE

**** Create an SSH key pair
Connection to the VMs are able through SSH whose authentication is based on
keys. It is highly recommended to create a pair of keys that will be used only
for this session. To that end you can type on your local machine:

: ssh-keygen -t rsa -f ~/.ssh/id_tp_omh -P ''

This commands creates two files:
- =~/.ssh.id_tp_omh=: the private counterpart of the SSH key pair;
- =~/.ssh.id_tp_omh.pub=: its public counterpart.

**** Boot two virtual machines
We can ask OVH to create virtual machines from its ~Infrastructure~ panel. From
here click on ~Actions > Add a server~ and select the following characteristics:
- Location: 'Gravelines (GRA3)';
- Distribution: 'Debian-9';
- Flavor: 'B2-7';
- Public key: give a name and provide the content of ~./ssh/id_tp_omh.pub~;
- Advanced options:
  + Read and provide the script below as post-installation script;
  + Link the machine to your private network.

#+INCLUDE: "lib/os-control.sh" src bash

After clicking on ~Launch now~, a new machine should appear in the interface.
You can validate the VM is active with ~openstack server list~. Also try to ping
and SSH to this machine:

: local_host:~/ ssh -i ~/.ssh/id_tp_omh debian@<public_ip_os-control>

Boot the second machine similarly but provide the following post-installation
script:

#+INCLUDE: "lib/os-compute1.sh" src bash

We should copy the private counterpart of the SSH key pair on the first VM so
that it can be used to ease the SSH connection to the second machine. To that
end we use ~scp~ - type from your local machine:

: local_host:~/ scp -i ~/.ssh/id_tp_omh ~/.ssh/id_tp_omh debian@<public_ip_os-control>:/home/debian/.ssh/id_rsa

Confirm you can SSH from ~os-control~ to ~os-compute1~:

: local_host:~/ ssh -i ~/.ssh/id_tp_omh debian@<public_ip_os-control>
: os-control:~/ ssh -i ~/.ssh/id_tp_omh debian@<private_ip_os-control>

** Finish the initialization of OpenStack
Wait the intervention of the instructor to finish the initialization
of the lab ({{{ie}}} access Horizon, ping VMs one their private Net,
make VMs ping the Internet).

*** Access Horizon
Horizon is accessible at http://192.168.0.249:80, thus make it
unreachable from your browser. To access Horizon, many possibilities
are offered to you:

- Lynx :: ~lynx~ is a text-based web browser for use in a terminal.
#+BEGIN_SRC bash
debian@os-control$ lynx http://192.168.0.249:80
#+END_SRC

- DNAT            :: Destination NAT (DNAT) changes the destination
     address of packets. We can use DNAT and tell the frontend
     ({{{ie}}}, ~debian@os-control~), which is publicly
     reachable at ~<public_ip_ens3>~, to change the destination of
     packet incoming on ~<public_ip_ens3>~ port 80 to
     ~192.168.0.249:80~. This makes Horizon accessible through
     http://<public_ip_ens3>:80.
#+BEGIN_SRC bash
debian@os-control$ sudo iptables -t nat -A PREROUTING\
  --dst <public_ip_ens3> -p tcp --dport 80\
  -j DNAT --to-destination 192.168.0.249:80
#+END_SRC

- SSH Tunnel      :: A SSH tunnel move the communication into a secure
     channel and allow a user to get an access to a local private
     service. We can get an access to Horizon by starting a SSH tunnel
     on our local machine. This provides an access to Horizon through
     http://localhost:8080.
#+BEGIN_SRC bash
my-fancy-zsh-prompt Î» â†’ ssh -NL 8080:192.168.0.249:80 \
  -l debian -i ~/.ssh/id_tp_omh <public_ip_ens3>
#+END_SRC

*** Ping VM from the Frontend                                      :noexport:
The neutron router called ~router~ makes the link between the public
and private network. If you want to ping your VMs from the Frontend
({{{ie}}}, ~debian@os-control~), then add a route that goes
through the router.

#+BEGIN_SRC
debian@os-control$ sudo ip route add 10.0.0.0/24 via\
  $(openstack router show router -c external_gateway_info -f value\
    |jq -r ".external_fixed_ips[0] | .ip_address")
#+END_SRC

*** VM ping the Internet
: sudo iptables -t nat -A POSTROUTING -o ens3 -j MASQUERADE

* OMH -- Online Mines Hosting
#+BEGIN_NOTE
Before doing that part, first remind basics of OpenStack by redoing
the "Play with OpenStack" section of the previous session (see [[file:../day1/SUBJECT.org::#sec:play-with-os][Day 1 â†’
Sec 3]]). Horizon is available behind the public IP of
~os-control~.
#+END_NOTE

Wordpress[fn:wordpress] is the most popular content management system
(CMS) in use on the Web. People use it to create websites, blogs or
applications. It is open-source, and based on PHP and MySQL under the
hood.

A common Wordpress deployment consists in two machines:
- ~wordpress-db~   :: A machine that contains the MySQL database for
     Wordpress.
- ~wordpress-app~  :: A machine that contains a web server that serves
     the Wordpress CMS.

The directory ~rsc/lib~ provides bash scripts to deploy the MySQL
database and the web server. As the DevOps of OMH -- Online Mines
Hosting -- your job is to automatize the deployment of a Wordpress on
your OpenStack. See the bash scripts in [[*Appendix][appendix]] for more information.
Also, [[*Clean the environment][clean your environment]] before going further.

** Clean the environment
When it comes the time to deal with real applications, we cannot use
cirros VMs anymore. A Cirros VM is good for testing because it starts
fast and has a small memory footprint. However, do not expect to
launch MySQL on a cirros.

We are going to run several Debian9 VMs in this section. But, a
Debian9 takes a lot more of resources to run. For this reason, you
have to release all your resources before going further.

Delete currently running VMs.
#+BEGIN_SRC bash
debian@os-control:~$ for vm in $(openstack server list -c Name -f value); do\
  echo "Delete ${vm}...";\
  openstack server delete "${vm}";\
done
#+END_SRC

# In the same manner, delete floating IPs.
# #+BEGIN_SRC bash
# debian@os-control:~$ for ip in $(openstack floating ip list -c "Floating IP Address" -f value); do\
#   echo "Delete ${ip}...";\
#   openstack floating ip delete "${ip}";\
# done
# #+END_SRC

** Wordpress MySQL Database                                        :noexport:
Start a VM with ~wordpress-db~ name, ~debian-9~ image, ~m1.small~
flavor, ~private~ network and ~admin~ key-pair. Also, provision your
VM with the next script thanks to the ~--user-data
~/rsc/lib/install-mariadb.sh~ option.

#+BEGIN_SRC bash
openstack server create --wait --image debian-9\
                               --flavor m1.small --network private\
                               --key-name admin\
                               --user-data ~/rsc/lib/install-mariadb.sh\
                               wordpress-db
#+END_SRC

** Wordpress Application                                           :noexport:
Start a VM with ~wordpress-app~ name, ~debian-9~ image, ~m1.small~
flavor, ~private~ network and ~admin~ key-pair. Also, provision your
VM with the next script thanks to the ~--user-data
~/rsc/lib/install-wp.sh~ option. Note that you need to provide the IP address
of the MySQL server to this script before running it.

#+BEGIN_SRC bash
openstack server create --wait --image debian-9\
                               --flavor m1.small --network private\
                               --key-name admin\
                               --user-data ~/rsc/lib/install-wp.sh\
                               wordpress-app
#+END_SRC

Then, attach a floating ip to that VM.
#+BEGIN_SRC bash
debian@os-control:~$ openstack server add floating ip\
  wordpress-wp\
  $(openstack floating ip create public -c floating_ip_address -f value)
#+END_SRC

Finally, you can reach WordPress.
#+BEGIN_SRC bash
debian@os-control:~$ lynx <floating_ip>/wp
#+END_SRC

* Automatize the deployment with Heat
[[https://docs.google.com/presentation/d/14Mzr_hMvH6AB7yUqUilbrnkxpQTTVAJnKZ1W-7zIE-0/edit#slide=id.p][/Dim's slides/]]

* Appendix
** reservation.yaml
#+INCLUDE: "lib/reservation.yml" src bash

** patch/galera.cnf
#+INCLUDE: "lib/patch/galera.cnf" src bash

** Installs MariaDB on Debian 9
#+INCLUDE: "lib/install-mariadb.sh" src bash

** Installs Wordpress on Debian 9
#+INCLUDE: "lib/install-wp.sh" src bash

* Footnotes

[fn:ovh] https://www.ovh.com/fr/cloud/
[fn:ovh-vrack] https://www.ovh.com/manager/cloud/index.html#/vrack
[fn:ovh-vrack-doc] https://docs.ovh.com/fr/public-cloud/utiliser-le-vrack-et-les-reseaux-prives-avec-les-instances-public-cloud/https://docs.ovh.com/fr/public-cloud/utiliser-le-vrack-et-les-reseaux-prives-avec-les-instances-public-cloud/
[fn:cloudinit] https://cloud-init.io/
[fn:cloudinit_modules] http://cloudinit.readthedocs.io/en/latest/topics/modules.html
[fn:wordpress] https://wordpress.org/
[fn:devstack] https://docs.openstack.org/devstack/latest/
[fn:puppet] https://docs.openstack.org/puppet-openstack-guide/latest/
[fn:kolla-ansible] https://docs.openstack.org/developer/kolla-ansible/
[fn:enos-paper] https://hal.inria.fr/hal-01415522v2
[fn:enos-code] https://github.com/BeyondTheClouds/enos
[fn:virtualbox-downloads] https://www.virtualbox.org/wiki/Downloads
[fn:vagrant-downloads] https://www.vagrantup.com/downloads.html
[fn:enos-box] http://enos.irisa.fr/vagrant-box/polytech.box
[fn:enos-provider] https://enos.readthedocs.io/en/latest/provider.html
[fn:enos-g5k-provider] https://enos.readthedocs.io/en/latest/provider/grid5000.html
[fn:enos-vagrant-provider] https://enos.readthedocs.io/en/latest/provider/vagrant.html
[fn:vagrantfile] https://www.vagrantup.com/docs/vagrantfile/index.html
[fn:cadvisor] https://github.com/google/cadvisor
[fn:collectd] https://collectd.org/
[fn:grafana] https://grafana.com/
[fn:rally] https://rally.readthedocs.io/en/latest/
[fn:shaker] https://pyshaker.readthedocs.io/en/latest/
[fn:rally-scenarios] https://github.com/openstack/rally/tree/master/rally/plugins/openstack/scenarios
[fn:shaker-scenarios] https://github.com/openstack/shaker/tree/master/shaker/scenarios/openstack
[fn:dvr] https://wiki.openstack.org/wiki/Neutron/DVR

# Local Variables:
# org-html-postamble: "<p class=\"author\">Author: %a</p>
# <p class=\"email\">Email: %e</p>
# <p class=\"github\">Find a typo, wanna make a proposition:
#  <a href=\"https://github.com/BeyondTheClouds/enos-scenarios/issues/new?title=tp-imt (Day 2)\">open an issue</a></p>
# <p class=\"date\">Last modification: %C</p>
# <p class=\"license\">This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-sa/4.0/\">Creative Commons Attribution-ShareAlike 4.0 International License</a>.</p>
# <p class=\"creator\">%c â€“ theme by
#  <a href=\"http://gongzhitaao.org/orgcss\">http://gongzhitaao.org/orgcss</a></p>"
# End:
